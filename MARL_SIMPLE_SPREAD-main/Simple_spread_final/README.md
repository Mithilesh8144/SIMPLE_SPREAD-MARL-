The simple_spread_final folder explores three distinct DQN approaches:
1) **Independent DQNs:** Three separate DQNs are trained, one for each agent. Each agent learns independently, without sharing information or parameters with other agents.
2) **Parameter Sharing DQN:** A single DQN is used to train all three agents.  The network's parameters (weights and biases) are shared across agents. This promotes cooperation by allowing agents to learn from each other's experiences.
The performance of both approaches is evaluated using the default frame configuration and a modified configuration using 100 frames, with results documented in the PNG files within the repository.  The PNG files visually illustrate and compare the performance metrics achieved by each approach under varying frame conditions.
